{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18734f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518fe3dd",
   "metadata": {},
   "source": [
    "## Création des nouvelles régions correspandantes au fichier météo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ddf88b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>﻿LIB_REG2</th>\n",
       "      <th>LIB_DEP</th>\n",
       "      <th>LIB_CODE</th>\n",
       "      <th>New_catetogorie</th>\n",
       "      <th>Region</th>\n",
       "      <th>SURF_2010</th>\n",
       "      <th>SURF_2011</th>\n",
       "      <th>SURF_2012</th>\n",
       "      <th>SURF_2013</th>\n",
       "      <th>SURF_2014</th>\n",
       "      <th>...</th>\n",
       "      <th>PROD_2016</th>\n",
       "      <th>PROD_2017</th>\n",
       "      <th>PROD_2018</th>\n",
       "      <th>PROD_2019</th>\n",
       "      <th>PROD_2020</th>\n",
       "      <th>PROD_2021</th>\n",
       "      <th>PROD_2022</th>\n",
       "      <th>PROD_2023</th>\n",
       "      <th>Numéro</th>\n",
       "      <th>new_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11 - Île-de-France</td>\n",
       "      <td>077 - Seine-et-Marne</td>\n",
       "      <td>01 - Blé tendre d'hiver et épeautre</td>\n",
       "      <td>Blé</td>\n",
       "      <td>Ile-de-France</td>\n",
       "      <td>135 199</td>\n",
       "      <td>142 512</td>\n",
       "      <td>137 830</td>\n",
       "      <td>140 610</td>\n",
       "      <td>139 130</td>\n",
       "      <td>...</td>\n",
       "      <td>5 589 600</td>\n",
       "      <td>11 009 925</td>\n",
       "      <td>10 081 225</td>\n",
       "      <td>11 760 760</td>\n",
       "      <td>8 800 715</td>\n",
       "      <td>10 958 490</td>\n",
       "      <td>10 320 700</td>\n",
       "      <td>10 472 850</td>\n",
       "      <td>77</td>\n",
       "      <td>ile-de-france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11 - Île-de-France</td>\n",
       "      <td>077 - Seine-et-Marne</td>\n",
       "      <td>03 - Total blé tendre (01 + 02)</td>\n",
       "      <td>Blé</td>\n",
       "      <td>Ile-de-France</td>\n",
       "      <td>135 518</td>\n",
       "      <td>142 872</td>\n",
       "      <td>138 240</td>\n",
       "      <td>141 210</td>\n",
       "      <td>139 620</td>\n",
       "      <td>...</td>\n",
       "      <td>5 599 800</td>\n",
       "      <td>11 043 135</td>\n",
       "      <td>10 108 175</td>\n",
       "      <td>11 814 000</td>\n",
       "      <td>8 901 585</td>\n",
       "      <td>11 019 495</td>\n",
       "      <td>10 401 450</td>\n",
       "      <td>10 514 841</td>\n",
       "      <td>77</td>\n",
       "      <td>ile-de-france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11 - Île-de-France</td>\n",
       "      <td>077 - Seine-et-Marne</td>\n",
       "      <td>06 - Total blé dur (04 + 05)</td>\n",
       "      <td>Blé</td>\n",
       "      <td>Ile-de-France</td>\n",
       "      <td>1 981</td>\n",
       "      <td>1 471</td>\n",
       "      <td>1 590</td>\n",
       "      <td>1 115</td>\n",
       "      <td>730</td>\n",
       "      <td>...</td>\n",
       "      <td>18 800</td>\n",
       "      <td>55 250</td>\n",
       "      <td>42 840</td>\n",
       "      <td>28 800</td>\n",
       "      <td>49 350</td>\n",
       "      <td>65 920</td>\n",
       "      <td>68 340</td>\n",
       "      <td>52 313</td>\n",
       "      <td>77</td>\n",
       "      <td>ile-de-france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11 - Île-de-France</td>\n",
       "      <td>077 - Seine-et-Marne</td>\n",
       "      <td>10 - Total orge et escourgeon (08 + 09)</td>\n",
       "      <td>Orge</td>\n",
       "      <td>Ile-de-France</td>\n",
       "      <td>40 473</td>\n",
       "      <td>42 389</td>\n",
       "      <td>43 680</td>\n",
       "      <td>42 325</td>\n",
       "      <td>45 900</td>\n",
       "      <td>...</td>\n",
       "      <td>2 646 320</td>\n",
       "      <td>3 912 250</td>\n",
       "      <td>3 752 460</td>\n",
       "      <td>4 971 470</td>\n",
       "      <td>3 566 115</td>\n",
       "      <td>3 902 290</td>\n",
       "      <td>3 869 845</td>\n",
       "      <td>4 213 297</td>\n",
       "      <td>77</td>\n",
       "      <td>ile-de-france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11 - Île-de-France</td>\n",
       "      <td>077 - Seine-et-Marne</td>\n",
       "      <td>13 - Total avoine (11 + 12)</td>\n",
       "      <td>Cérélaes(autres)</td>\n",
       "      <td>Ile-de-France</td>\n",
       "      <td>1 637</td>\n",
       "      <td>1 163</td>\n",
       "      <td>1 400</td>\n",
       "      <td>1 765</td>\n",
       "      <td>1 840</td>\n",
       "      <td>...</td>\n",
       "      <td>80 000</td>\n",
       "      <td>150 300</td>\n",
       "      <td>124 800</td>\n",
       "      <td>98 580</td>\n",
       "      <td>99 750</td>\n",
       "      <td>112 860</td>\n",
       "      <td>77 585</td>\n",
       "      <td>68 288</td>\n",
       "      <td>77</td>\n",
       "      <td>ile-de-france</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ﻿LIB_REG2               LIB_DEP  \\\n",
       "0  11 - Île-de-France  077 - Seine-et-Marne   \n",
       "1  11 - Île-de-France  077 - Seine-et-Marne   \n",
       "2  11 - Île-de-France  077 - Seine-et-Marne   \n",
       "3  11 - Île-de-France  077 - Seine-et-Marne   \n",
       "4  11 - Île-de-France  077 - Seine-et-Marne   \n",
       "\n",
       "                                  LIB_CODE   New_catetogorie         Region  \\\n",
       "0      01 - Blé tendre d'hiver et épeautre               Blé  Ile-de-France   \n",
       "1          03 - Total blé tendre (01 + 02)               Blé  Ile-de-France   \n",
       "2             06 - Total blé dur (04 + 05)               Blé  Ile-de-France   \n",
       "3  10 - Total orge et escourgeon (08 + 09)              Orge  Ile-de-France   \n",
       "4              13 - Total avoine (11 + 12)  Cérélaes(autres)  Ile-de-France   \n",
       "\n",
       "  SURF_2010 SURF_2011 SURF_2012 SURF_2013 SURF_2014  ...  PROD_2016  \\\n",
       "0   135 199   142 512   137 830   140 610   139 130  ...  5 589 600   \n",
       "1   135 518   142 872   138 240   141 210   139 620  ...  5 599 800   \n",
       "2     1 981     1 471     1 590     1 115       730  ...     18 800   \n",
       "3    40 473    42 389    43 680    42 325    45 900  ...  2 646 320   \n",
       "4     1 637     1 163     1 400     1 765     1 840  ...     80 000   \n",
       "\n",
       "    PROD_2017   PROD_2018   PROD_2019  PROD_2020   PROD_2021   PROD_2022  \\\n",
       "0  11 009 925  10 081 225  11 760 760  8 800 715  10 958 490  10 320 700   \n",
       "1  11 043 135  10 108 175  11 814 000  8 901 585  11 019 495  10 401 450   \n",
       "2      55 250      42 840      28 800     49 350      65 920      68 340   \n",
       "3   3 912 250   3 752 460   4 971 470  3 566 115   3 902 290   3 869 845   \n",
       "4     150 300     124 800      98 580     99 750     112 860      77 585   \n",
       "\n",
       "    PROD_2023 Numéro     new_region  \n",
       "0  10 472 850     77  ile-de-france  \n",
       "1  10 514 841     77  ile-de-france  \n",
       "2      52 313     77  ile-de-france  \n",
       "3   4 213 297     77  ile-de-france  \n",
       "4      68 288     77  ile-de-france  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Nouveau dictionnaire des régions et départements\n",
    "regions_departments = {\n",
    "    'alsace': ['67', '68'],\n",
    "    'aquitaine': ['24', '33', '40', '47', '64', '79', '86'],\n",
    "    'ardeche': ['07'],\n",
    "    'auvergne': ['03', '15', '43', '63', '01'],\n",
    "    'bourgogne': ['21', '58', '71', '89', '10'],\n",
    "    'bretagne': ['22', '29', '35', '56'],\n",
    "    'camargue': ['13', '30'],\n",
    "    'centre': ['18', '28', '36', '37', '41', '45'],\n",
    "    'cevennes-lozere': ['48'],\n",
    "    'charentes': ['16', '17'],\n",
    "    'corse': ['02A', '02B', '971', '972', '973', '974', '976'],\n",
    "    'drome': ['26'],\n",
    "    'franche-comte': ['25', '39', '70', '90'],\n",
    "    'ile-de-france': ['75', '77', '78', '91', '92', '93', '94', '95'],\n",
    "    'ile-de-re': ['17'],\n",
    "    'jura': ['39'],\n",
    "    'landes': ['40'],\n",
    "    'limousin': ['19', '23', '87'],\n",
    "    'lorraine': ['54', '55', '57', '88', '08', '51', '52'],\n",
    "    'lot': ['46'],\n",
    "    'lyonnais': ['69', '38', '42', '73', '74'],\n",
    "    'midi-pyrenees': ['09', '12', '31', '32', '46', '65', '81', '82', '11', '34', '66'],\n",
    "    'midi-toulousain': ['31', '32', '82'],\n",
    "    'normandie': ['14', '27', '50', '61', '76'],\n",
    "    'pays-basque': ['64'],\n",
    "    'pays-de-la-loire': ['44', '49', '53', '72', '85'],\n",
    "    'perigord-dordogne': ['24'],\n",
    "    'picardie': ['02', '60', '80', '59', '62'],\n",
    "    'provence-alpes-c-te-d-azur': ['04', '05', '06', '13', '83', '84'],\n",
    "    'vendee': ['85']\n",
    "}\n",
    "\n",
    "\n",
    "# Fonction pour obtenir la région d'un département\n",
    "def get_region(department):\n",
    "    for region, departments in regions_departments.items():\n",
    "        if department in departments:\n",
    "            return region\n",
    "    return 'Unknown'\n",
    "\n",
    "# Lire le fichier CSV\n",
    "file_path = 'Fichier_sources_rendement.csv'\n",
    "df = pd.read_csv(file_path, sep=None, engine='python', on_bad_lines='skip')\n",
    "\n",
    "# Extraire le numéro du département sans les zéros initiaux et gérer les cas alphanumériques\n",
    "def extract_dept_number(dept):\n",
    "    num = dept.split(' - ')[0]\n",
    "    if num in ['2A', '2B']:\n",
    "        return num  # Retourne les numéros alphanumériques tels quels ('2A', '2B')\n",
    "    try:\n",
    "        return str(int(num)).zfill(2)  # Convertit les numéros comme '001' en '01', '002' en '02'\n",
    "    except ValueError:\n",
    "        return num  # Retourne les autres cas tels quels\n",
    "\n",
    "# Ajouter la colonne 'Numéro'\n",
    "df['Numéro'] = df['LIB_DEP'].apply(extract_dept_number)\n",
    "\n",
    "# Ajouter la colonne 'new_region'\n",
    "df['new_region'] = df['Numéro'].apply(get_region)\n",
    "\n",
    "# # Sauvegarder le fichier modifié\n",
    "# output_path = 'Fichier_sources_rendement_avec_regions.csv'\n",
    "# df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "# Afficher les premières lignes du dataframe modifié\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcb9f5d",
   "metadata": {},
   "source": [
    "## Transposé du fichier source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36b94d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['﻿LIB_REG2', 'LIB_DEP', 'LIB_CODE', 'New_catetogorie', 'Region',\n",
      "       'SURF_2010', 'SURF_2011', 'SURF_2012', 'SURF_2013', 'SURF_2014',\n",
      "       'SURF_2015', 'SURF_2016', 'SURF_2017', 'SURF_2018', 'SURF_2019',\n",
      "       'SURF_2020', 'SURF_2021', 'SURF_2022', 'SURF_2023', 'REND_2010',\n",
      "       'REND_2011', 'REND_2012', 'REND_2013', 'REND_2014', 'REND_2015',\n",
      "       'REND_2016', 'REND_2017', 'REND_2018', 'REND_2019', 'REND_2020',\n",
      "       'REND_2021', 'REND_2022', 'REND_2023', 'PROD_2010', 'PROD_2011',\n",
      "       'PROD_2012', 'PROD_2013', 'PROD_2014', 'PROD_2015', 'PROD_2016',\n",
      "       'PROD_2017', 'PROD_2018', 'PROD_2019', 'PROD_2020', 'PROD_2021',\n",
      "       'PROD_2022', 'PROD_2023', 'Numéro', 'new_region'],\n",
      "      dtype='object')\n",
      "Index(['LIB_DEP', 'LIB_CODE', 'New_catetogorie', 'Region', 'new_region',\n",
      "       'Year', 'PROD', 'REND', 'SURF'],\n",
      "      dtype='object', name='Type')\n",
      "  Departement      Crops_sub Crops            New_Region Old_Region  Year  \\\n",
      "0   001 - Ain  01 - Abricots   Nan  Auvergne-Rhone-Alpes   auvergne  2010   \n",
      "1   001 - Ain  01 - Abricots   Nan  Auvergne-Rhone-Alpes   auvergne  2011   \n",
      "2   001 - Ain  01 - Abricots   Nan  Auvergne-Rhone-Alpes   auvergne  2012   \n",
      "3   001 - Ain  01 - Abricots   Nan  Auvergne-Rhone-Alpes   auvergne  2013   \n",
      "4   001 - Ain  01 - Abricots   Nan  Auvergne-Rhone-Alpes   auvergne  2014   \n",
      "\n",
      "  Production Rendement Surface  \n",
      "0          0       NaN       0  \n",
      "1          0       NaN       0  \n",
      "2          0       NaN       0  \n",
      "3          0       NaN       0  \n",
      "4          0       NaN       0  \n",
      "Transformation terminée et fichier sauvegardé sous 'test_14.csv'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Departement</th>\n",
       "      <th>Crops_sub</th>\n",
       "      <th>Crops</th>\n",
       "      <th>New_Region</th>\n",
       "      <th>Old_Region</th>\n",
       "      <th>Year</th>\n",
       "      <th>Production</th>\n",
       "      <th>Rendement</th>\n",
       "      <th>Surface</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001 - Ain</td>\n",
       "      <td>01 - Abricots</td>\n",
       "      <td>Nan</td>\n",
       "      <td>Auvergne-Rhone-Alpes</td>\n",
       "      <td>auvergne</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001 - Ain</td>\n",
       "      <td>01 - Abricots</td>\n",
       "      <td>Nan</td>\n",
       "      <td>Auvergne-Rhone-Alpes</td>\n",
       "      <td>auvergne</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001 - Ain</td>\n",
       "      <td>01 - Abricots</td>\n",
       "      <td>Nan</td>\n",
       "      <td>Auvergne-Rhone-Alpes</td>\n",
       "      <td>auvergne</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001 - Ain</td>\n",
       "      <td>01 - Abricots</td>\n",
       "      <td>Nan</td>\n",
       "      <td>Auvergne-Rhone-Alpes</td>\n",
       "      <td>auvergne</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001 - Ain</td>\n",
       "      <td>01 - Abricots</td>\n",
       "      <td>Nan</td>\n",
       "      <td>Auvergne-Rhone-Alpes</td>\n",
       "      <td>auvergne</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Departement      Crops_sub Crops            New_Region Old_Region  Year  \\\n",
       "0   001 - Ain  01 - Abricots   Nan  Auvergne-Rhone-Alpes   auvergne  2010   \n",
       "1   001 - Ain  01 - Abricots   Nan  Auvergne-Rhone-Alpes   auvergne  2011   \n",
       "2   001 - Ain  01 - Abricots   Nan  Auvergne-Rhone-Alpes   auvergne  2012   \n",
       "3   001 - Ain  01 - Abricots   Nan  Auvergne-Rhone-Alpes   auvergne  2013   \n",
       "4   001 - Ain  01 - Abricots   Nan  Auvergne-Rhone-Alpes   auvergne  2014   \n",
       "\n",
       "  Production Rendement Surface  \n",
       "0          0       NaN       0  \n",
       "1          0       NaN       0  \n",
       "2          0       NaN       0  \n",
       "3          0       NaN       0  \n",
       "4          0       NaN       0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Corriger le nom de la colonne si nécessaire\n",
    "df.columns = df.columns.str.strip()  # Retirer les espaces au début et à la fin des noms de colonnes\n",
    "\n",
    "# Vérifiez les colonnes disponibles dans le DataFrame\n",
    "print(df.columns)\n",
    "\n",
    "# Ajuster la liste 'id_vars' selon les colonnes disponibles\n",
    "id_vars = ['LIB_DEP', 'LIB_CODE', 'New_catetogorie', 'Region', 'new_region']\n",
    "\n",
    "# Si une des colonnes n'existe pas, retirez-la de la liste\n",
    "id_vars = [col for col in id_vars if col in df.columns]\n",
    "\n",
    "# Identifier dynamiquement les colonnes pour value_vars\n",
    "value_vars = [col for col in df.columns if col.startswith('SURF_') or col.startswith('PROD_') or col.startswith('REND_')]\n",
    "\n",
    "# Transformer les données\n",
    "data_long_format = pd.melt(df, \n",
    "                           id_vars=id_vars, \n",
    "                           value_vars=value_vars, \n",
    "                           var_name='Variable', \n",
    "                           value_name='Value')\n",
    "\n",
    "# Extraire l'année et le type de donnée (Surface, Production ou Rendement)\n",
    "data_long_format['Year'] = data_long_format['Variable'].str.extract('(\\d+)', expand=False)\n",
    "data_long_format['Type'] = data_long_format['Variable'].str[:4]\n",
    "\n",
    "# Réorganiser les données\n",
    "index_columns = id_vars + ['Year']\n",
    "data_pivot = data_long_format.pivot_table(index=index_columns, columns='Type', values='Value', aggfunc='first').reset_index()\n",
    "\n",
    "# Vérifiez les colonnes actuelles de data_pivot\n",
    "print(data_pivot.columns)\n",
    "\n",
    "# Renommer les colonnes selon les spécifications\n",
    "data_pivot.columns.name = None\n",
    "column_rename_map = {\n",
    "    'LIB_DEP': 'Departement',\n",
    "    'LIB_CODE': 'Crops_sub',\n",
    "    'New_catetogorie': 'Crops',\n",
    "    'Region': 'New_Region',\n",
    "    'new_region': 'Old_Region',\n",
    "    'Year': 'Year',\n",
    "    'PROD': 'Production',\n",
    "    'REND': 'Rendement',\n",
    "    'SURF': 'Surface'\n",
    "}\n",
    "\n",
    "data_pivot = data_pivot.rename(columns=column_rename_map)\n",
    "\n",
    "# Sélectionner et renommer les colonnes finales\n",
    "final_columns = ['Departement', 'Crops_sub', 'Crops', 'New_Region', 'Old_Region', 'Year', 'Production', 'Rendement', 'Surface']\n",
    "final_data = data_pivot[final_columns]\n",
    "\n",
    "# Afficher les premières lignes des données transformées\n",
    "print(final_data.head())\n",
    "\n",
    "# Sauvegarder le nouveau fichier avec encodage UTF-8\n",
    "# file_path_test14 = 'test_14.csv'\n",
    "# final_data.to_csv(file_path_test14, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Transformation terminée et fichier sauvegardé sous 'test_14.csv'.\")\n",
    "\n",
    "final_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b122b101",
   "metadata": {},
   "source": [
    "## Suppression des surface nul et des Crops_group = Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5656eada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données initiales :\n",
      "  Departement      Crops_sub Crops            New_Region Old_Region  Year  \\\n",
      "0   001 - Ain  01 - Abricots   Nan  Auvergne-Rhone-Alpes   auvergne  2010   \n",
      "1   001 - Ain  01 - Abricots   Nan  Auvergne-Rhone-Alpes   auvergne  2011   \n",
      "2   001 - Ain  01 - Abricots   Nan  Auvergne-Rhone-Alpes   auvergne  2012   \n",
      "3   001 - Ain  01 - Abricots   Nan  Auvergne-Rhone-Alpes   auvergne  2013   \n",
      "4   001 - Ain  01 - Abricots   Nan  Auvergne-Rhone-Alpes   auvergne  2014   \n",
      "\n",
      "  Production Rendement Surface  \n",
      "0          0       NaN       0  \n",
      "1          0       NaN       0  \n",
      "2          0       NaN       0  \n",
      "3          0       NaN       0  \n",
      "4          0       NaN       0  \n",
      "\n",
      "Types des colonnes après conversion :\n",
      "Departement     object\n",
      "Crops_sub       object\n",
      "Crops           object\n",
      "New_Region      object\n",
      "Old_Region      object\n",
      "Year             int64\n",
      "Production     float64\n",
      "Rendement      float64\n",
      "Surface        float64\n",
      "dtype: object\n",
      "\n",
      "Données après suppression :\n",
      "   Departement                            Crops_sub    Crops  \\\n",
      "24   001 - Ain                      01 - Artichauts  légumes   \n",
      "25   001 - Ain                      01 - Artichauts  légumes   \n",
      "26   001 - Ain                      01 - Artichauts  légumes   \n",
      "27   001 - Ain                      01 - Artichauts  légumes   \n",
      "42   001 - Ain  01 - Blé tendre d'hiver et épeautre      Blé   \n",
      "\n",
      "              New_Region Old_Region  Year  Production  Rendement  Surface  \n",
      "24  Auvergne-Rhone-Alpes   auvergne  2020        53.0       53.0      1.0  \n",
      "25  Auvergne-Rhone-Alpes   auvergne  2021        58.0       58.0      1.0  \n",
      "26  Auvergne-Rhone-Alpes   auvergne  2022        41.0       41.0      1.0  \n",
      "27  Auvergne-Rhone-Alpes   auvergne  2023        46.0       46.0      1.0  \n",
      "42  Auvergne-Rhone-Alpes   auvergne  2010   2393064.0       72.0  33237.0  \n",
      "\n",
      "Les lignes avec Surface = 0, Surface vide, Surface = -1 et Crops vide ont été supprimées. Fichier sauvegardé sous 'test_14_filtered.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Afficher les premières lignes pour vérifier les données\n",
    "print(\"Données initiales :\")\n",
    "print(final_data.head())\n",
    "\n",
    "# Convertir les colonnes 'Production', 'Rendement' et 'Surface' en type float\n",
    "final_data['Production'] = pd.to_numeric(final_data['Production'].astype(str).str.replace(' ', '').str.replace(',', '.'), errors='coerce')\n",
    "final_data['Rendement'] = pd.to_numeric(final_data['Rendement'].astype(str).str.replace(' ', '').str.replace(',', '.'), errors='coerce')\n",
    "final_data['Surface'] = pd.to_numeric(final_data['Surface'].astype(str).str.replace(' ', ''), errors='coerce')\n",
    "\n",
    "# Convertir la colonne 'Year' en type datetime (année)\n",
    "final_data['Year'] = pd.to_datetime(final_data['Year'], format='%Y').dt.year\n",
    "\n",
    "# Vérifier les types de données pour diagnostiquer les problèmes potentiels\n",
    "print(\"\\nTypes des colonnes après conversion :\")\n",
    "print(final_data.dtypes)\n",
    "\n",
    "# Remplacer les valeurs 'Nan' dans la colonne 'Crops' par np.nan\n",
    "final_data['Crops'] = final_data['Crops'].replace('Nan', np.nan)\n",
    "\n",
    "# Supprimer les lignes où la surface est égale à 0, vide ou égale à -1\n",
    "final_data = final_data[(final_data['Surface'] != 0) & (final_data['Surface'].notna()) & (final_data['Surface'] != -1)]\n",
    "\n",
    "# Supprimer les lignes où Crops est NaN\n",
    "final_data = final_data[final_data['Crops'].notna()]\n",
    "\n",
    "# Afficher les premières lignes après suppression\n",
    "print(\"\\nDonnées après suppression :\")\n",
    "print(final_data.head())\n",
    "\n",
    "# Sauvegarder le fichier modifié\n",
    "# file_path_filtered = 'test_14_filtered.csv'\n",
    "# final_data.to_csv(file_path_filtered, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"\\nLes lignes avec Surface = 0, Surface vide, Surface = -1 et Crops vide ont été supprimées. Fichier sauvegardé sous 'test_14_filtered.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2515cba2",
   "metadata": {},
   "source": [
    "## Calcul des variables météo annuelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c7af891",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes disponibles dans le DataFrame :\n",
      "Index(['Température moyenne', 'Température maximale', 'Température minimale',\n",
      "       'Température maximale maximum', 'Température minimale maximum',\n",
      "       'Température minimale minimum', 'Vitesse du vent',\n",
      "       'Température du vent', 'Précipitations moyennes par jour',\n",
      "       'Record de précipitations sur une journée', 'Humidité', 'Visibilité',\n",
      "       'Couverture nuageuse', 'region', 'year', 'month'],\n",
      "      dtype='object')\n",
      "Données chargées :\n",
      "   Température moyenne  Température maximale  Température minimale  \\\n",
      "0                    5                     7                     3   \n",
      "1                   -1                     1                    -3   \n",
      "2                    1                     4                    -1   \n",
      "3                    0                     2                    -2   \n",
      "4                    1                     2                    -1   \n",
      "\n",
      "   Température maximale maximum  Température minimale maximum  \\\n",
      "0                            13                            10   \n",
      "1                             8                             4   \n",
      "2                             9                             6   \n",
      "3                            10                             5   \n",
      "4                             8                             6   \n",
      "\n",
      "   Température minimale minimum  Vitesse du vent  Température du vent  \\\n",
      "0                            -8               24                   -1   \n",
      "1                           -14               14                   -7   \n",
      "2                           -16               17                   -5   \n",
      "3                           -15               16                   -6   \n",
      "4                           -14               16                   -5   \n",
      "\n",
      "   Précipitations moyennes par jour  Record de précipitations sur une journée  \\\n",
      "0                                 4                                        19   \n",
      "1                                 3                                        16   \n",
      "2                                 4                                        47   \n",
      "3                                 5                                        30   \n",
      "4                                 3                                        22   \n",
      "\n",
      "   Humidité  Visibilité  Couverture nuageuse     region  year    month  \\\n",
      "0        89           9                   48     vendee  2010  janvier   \n",
      "1        95           6                   65     alsace  2010  janvier   \n",
      "2        91           8                   55    ardeche  2010  janvier   \n",
      "3        92           7                   62   auvergne  2010  janvier   \n",
      "4        92           8                   58  bourgogne  2010  janvier   \n",
      "\n",
      "   Précipitations mensuelles  \n",
      "0                        120  \n",
      "1                         90  \n",
      "2                        120  \n",
      "3                        150  \n",
      "4                         90  \n",
      "     region  year  temp_moyenne  temp_max  temp_min  vitesse_vent  temp_vent  \\\n",
      "0    alsace  2010     10.166667        27        -4     13.833333   4.583333   \n",
      "1    alsace  2011     12.166667        25        -1     12.250000   6.666667   \n",
      "2    alsace  2012     11.250000        26        -6     13.083333   5.916667   \n",
      "3    alsace  2013     11.000000        28        -3     12.750000   6.000000   \n",
      "4    alsace  2014     12.833333        25         2     12.083333   7.583333   \n",
      "..      ...   ...           ...       ...       ...           ...        ...   \n",
      "415  vendee  2019     14.333333        25         5     22.916667   9.666667   \n",
      "416  vendee  2020     14.250000        24         7     23.750000  10.166667   \n",
      "417  vendee  2021     13.500000        24         5     23.166667   8.416667   \n",
      "418  vendee  2022     15.000000        29         5     22.916667   9.833333   \n",
      "419  vendee  2023     14.666667        24         5     24.500000  10.250000   \n",
      "\n",
      "     precip_sum  record_precip  humidite_moy  visibilite_moy  \\\n",
      "0          1500             69     91.750000        8.083333   \n",
      "1          1200             45     89.416667        8.833333   \n",
      "2          1560             53     90.833333        8.750000   \n",
      "3          1500             49     90.583333        8.750000   \n",
      "4          1140             42     89.333333        9.083333   \n",
      "..          ...            ...           ...             ...   \n",
      "415        1320             44     85.833333       10.000000   \n",
      "416        1320             51     85.583333        9.916667   \n",
      "417         750             64     85.250000        9.916667   \n",
      "418         420             11     84.500000       10.000000   \n",
      "419         510             44     85.583333       10.000000   \n",
      "\n",
      "     couv_nuageuse_moy  jours_chaleur  jours_froid  jours_humidite_basse  \\\n",
      "0            48.083333              6            6                     4   \n",
      "1            35.250000              6            6                     3   \n",
      "2            40.000000              5            7                     6   \n",
      "3            44.333333              6            5                     5   \n",
      "4            39.000000              7            5                     5   \n",
      "..                 ...            ...          ...                   ...   \n",
      "415          42.166667              5            7                     4   \n",
      "416          50.166667              5            7                     5   \n",
      "417          43.583333              6            6                     7   \n",
      "418          41.833333              6            6                     4   \n",
      "419          47.916667              6            6                     3   \n",
      "\n",
      "     jours_precip_consecutifs  \n",
      "0                           2  \n",
      "1                           3  \n",
      "2                           3  \n",
      "3                           3  \n",
      "4                           2  \n",
      "..                        ...  \n",
      "415                         3  \n",
      "416                         3  \n",
      "417                         2  \n",
      "418                         2  \n",
      "419                         3  \n",
      "\n",
      "[420 rows x 16 columns]\n",
      "\n",
      "Fichier sauvegardé sous 'meteo_data_all_new.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Charger le fichier avec différents encodages et délimiteurs\n",
    "file_path = 'meteo_data_All.csv'  \n",
    "\n",
    "# Essayer avec utf-8 et le point-virgule comme délimiteur\n",
    "try:\n",
    "    df = pd.read_csv(file_path, encoding='utf-8', delimiter=';')\n",
    "except UnicodeDecodeError:\n",
    "    # Si utf-8 échoue, essayer avec latin1\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='latin1', delimiter=';')\n",
    "    except UnicodeDecodeError:\n",
    "        # Si latin1 échoue, essayer avec utf-8 et une virgule comme délimiteur\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='utf-8', delimiter=',')\n",
    "        except UnicodeDecodeError:\n",
    "            # Si toutes les autres tentatives échouent, essayer avec latin1 et une virgule comme délimiteur\n",
    "            df = pd.read_csv(file_path, encoding='latin1', delimiter=',')\n",
    "\n",
    "# Corriger les noms de colonnes encodés incorrectement\n",
    "df.columns = [col.encode('latin1').decode('utf-8') for col in df.columns]\n",
    "\n",
    "# Afficher les colonnes disponibles pour vérifier le chargement\n",
    "print(\"Colonnes disponibles dans le DataFrame :\")\n",
    "print(df.columns)\n",
    "\n",
    "# Multiplier les précipitations moyennes par jour par 30 pour obtenir les précipitations mensuelles si la colonne existe\n",
    "if 'Précipitations moyennes par jour' in df.columns:\n",
    "    df['Précipitations mensuelles'] = df['Précipitations moyennes par jour'] * 30\n",
    "    # Afficher les premières lignes pour vérifier le chargement et les nouvelles colonnes\n",
    "    print(\"Données chargées :\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"La colonne 'Précipitations moyennes par jour' n'existe pas dans le DataFrame.\")\n",
    "\n",
    "# Calcul des variables par région et par année\n",
    "df_region_year = df.groupby(['region', 'year']).agg({\n",
    "    'Température moyenne': 'mean',\n",
    "    'Température maximale': 'max', \n",
    "    'Température minimale': 'min',\n",
    "    'Vitesse du vent': 'mean',\n",
    "    'Température du vent': 'mean', \n",
    "    'Précipitations mensuelles': 'sum',  # On utilise 'sum' pour obtenir les précipitations annuelles\n",
    "    'Record de précipitations sur une journée': 'max',\n",
    "    'Humidité': 'mean',\n",
    "    'Visibilité': 'mean', \n",
    "    'Couverture nuageuse': 'mean'\n",
    "})\n",
    "\n",
    "# Calcul du nombre de jours où la température a dépassé la moyenne annuelle\n",
    "df_temp_sup = df.groupby(['region', 'year', 'month']).agg({'Température moyenne': 'mean'})\n",
    "df_temp_sup = df_temp_sup.reset_index()\n",
    "df_temp_sup['moy_annuelle'] = df_temp_sup.groupby(['region', 'year'])['Température moyenne'].transform('mean')\n",
    "df_temp_sup['jours_chaleur'] = (df_temp_sup['Température moyenne'] > df_temp_sup['moy_annuelle']).astype(int)\n",
    "df_temp_sup = df_temp_sup.groupby(['region', 'year'])['jours_chaleur'].sum()\n",
    "\n",
    "# Calcul du nombre de jours où la température a été en dessous de la moyenne annuelle \n",
    "df_temp_inf = df.groupby(['region', 'year', 'month']).agg({'Température moyenne': 'mean'})  \n",
    "df_temp_inf = df_temp_inf.reset_index()\n",
    "df_temp_inf['moy_annuelle'] = df_temp_inf.groupby(['region', 'year'])['Température moyenne'].transform('mean')\n",
    "df_temp_inf['jours_froid'] = (df_temp_inf['Température moyenne'] < df_temp_inf['moy_annuelle']).astype(int)\n",
    "df_temp_inf = df_temp_inf.groupby(['region', 'year'])['jours_froid'].sum()\n",
    "\n",
    "# Calcul du nombre de jours où l'humidité a été en dessous de la moyenne annuelle\n",
    "df_humidite = df.groupby(['region', 'year', 'month']).agg({'Humidité': 'mean'})\n",
    "df_humidite = df_humidite.reset_index() \n",
    "df_humidite['moy_annuelle'] = df_humidite.groupby(['region', 'year'])['Humidité'].transform('mean')\n",
    "df_humidite['jours_humidite_basse'] = (df_humidite['Humidité'] < df_humidite['moy_annuelle']).astype(int)\n",
    "df_humidite = df_humidite.groupby(['region', 'year'])['jours_humidite_basse'].sum()\n",
    "\n",
    "# Calcul du nombre de jours consécutifs de précipitations supérieures à la moyenne\n",
    "df['precip_sup_moy'] = df.groupby(['region', 'year'])['Précipitations moyennes par jour'].transform(lambda x: x > x.mean())\n",
    "df['jours_precip_consecutifs'] = df.groupby(['region', 'year'])['precip_sup_moy'].transform(lambda x: x * (x.groupby((x != x.shift()).cumsum()).cumcount() + 1))\n",
    "df_precip = df.groupby(['region', 'year'])['jours_precip_consecutifs'].max()\n",
    "\n",
    "# Fusion des dataframes\n",
    "df_final = pd.concat([df_region_year, df_temp_sup, df_temp_inf, df_humidite, df_precip], axis=1)\n",
    "df_final = df_final.reset_index()\n",
    "\n",
    "# Renommage des colonnes\n",
    "df_final.columns = ['region', 'year', 'temp_moyenne', 'temp_max', 'temp_min', 'vitesse_vent', 'temp_vent', \n",
    "                    'precip_sum', 'record_precip', 'humidite_moy', 'visibilite_moy', 'couv_nuageuse_moy',\n",
    "                    'jours_chaleur', 'jours_froid', 'jours_humidite_basse', 'jours_precip_consecutifs']\n",
    "\n",
    "print(df_final)\n",
    "\n",
    "# Sauvegarder le fichier modifié\n",
    "output_path = 'meteo_data_all_new.csv'\n",
    "df_final.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"\\nFichier sauvegardé sous 'meteo_data_all_new.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f82f31",
   "metadata": {},
   "source": [
    "## Merge les data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33c0213a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes de final_data :\n",
      "Index(['Departement', 'Crops_sub', 'Crops', 'New_Region', 'Old_Region', 'Year',\n",
      "       'Production', 'Rendement', 'Surface'],\n",
      "      dtype='object')\n",
      "\n",
      "Colonnes de df_final :\n",
      "Index(['region', 'year', 'temp_moyenne', 'temp_max', 'temp_min',\n",
      "       'vitesse_vent', 'temp_vent', 'precip_sum', 'record_precip',\n",
      "       'humidite_moy', 'visibilite_moy', 'couv_nuageuse_moy', 'jours_chaleur',\n",
      "       'jours_froid', 'jours_humidite_basse', 'jours_precip_consecutifs'],\n",
      "      dtype='object')\n",
      "\n",
      "DataFrame fusionné :\n",
      "  Departement        Crops_sub    Crops            New_Region Old_Region  \\\n",
      "0   001 - Ain  01 - Artichauts  légumes  Auvergne-Rhone-Alpes   auvergne   \n",
      "1   001 - Ain  01 - Artichauts  légumes  Auvergne-Rhone-Alpes   auvergne   \n",
      "2   001 - Ain  01 - Artichauts  légumes  Auvergne-Rhone-Alpes   auvergne   \n",
      "3   001 - Ain  01 - Artichauts  légumes  Auvergne-Rhone-Alpes   auvergne   \n",
      "4   001 - Ain  01 - Artichauts  légumes  Auvergne-Rhone-Alpes   auvergne   \n",
      "\n",
      "   Year  Production  Rendement  Surface    region  ...  temp_vent  precip_sum  \\\n",
      "0  2020        53.0       53.0      1.0  auvergne  ...   3.750000        1500   \n",
      "1  2020        53.0       53.0      1.0  auvergne  ...   5.833333        1290   \n",
      "2  2020        53.0       53.0      1.0  auvergne  ...   4.750000        1530   \n",
      "3  2020        53.0       53.0      1.0  auvergne  ...   4.500000        1530   \n",
      "4  2020        53.0       53.0      1.0  auvergne  ...   6.083333        1380   \n",
      "\n",
      "   record_precip  humidite_moy  visibilite_moy  couv_nuageuse_moy  \\\n",
      "0             92     91.916667        7.916667          49.833333   \n",
      "1             59     91.916667        8.083333          44.083333   \n",
      "2             63     93.166667        7.916667          46.916667   \n",
      "3             54     92.583333        7.750000          49.833333   \n",
      "4             77     92.500000        8.250000          45.000000   \n",
      "\n",
      "   jours_chaleur  jours_froid  jours_humidite_basse  jours_precip_consecutifs  \n",
      "0              7            5                     4                         2  \n",
      "1              7            5                     4                         4  \n",
      "2              6            6                     7                         5  \n",
      "3              5            6                     5                         3  \n",
      "4              6            6                     4                         4  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Supposons que final_data et df_final sont les deux dataframe\n",
    "\n",
    "# Afficher les premières lignes des DataFrames pour vérifier les colonnes disponibles\n",
    "print(\"Colonnes de final_data :\")\n",
    "print(final_data.columns)\n",
    "print(\"\\nColonnes de df_final :\")\n",
    "print(df_final.columns)\n",
    "\n",
    "# Fusionner les DataFrames sur les colonnes 'Old_Region' de final_data et 'region' de df_final\n",
    "result_df = pd.merge(final_data, df_final, left_on='Old_Region', right_on='region', how='left')\n",
    "\n",
    "# Sauvegarder le fichier résultant\n",
    "output_path = 'Crops_Data.csv'\n",
    "result_df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "# Afficher les premières lignes du dataframe modifié\n",
    "print(\"\\nDataFrame fusionné :\")\n",
    "print(result_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b0278c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
